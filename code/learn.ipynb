{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed4cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from utils import find_assistant_token_end\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab0a335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605e979b12d74ac2a46cf72f5461a1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/Llama-3.1-8B-Instruct\", device_map=\"auto\", dtype=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8ff5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nlsasfs/home/isea/isea10/aansh/introspection/data/exp1/multi_token_completions/simple_narrative_continuations_category_1.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "example = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1490ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"\n",
    "Complete the following sentence:\n",
    "{example[\"prompt\"]} \n",
    "\"\"\"\n",
    "message_1 = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt}, \n",
    "    {\"role\": \"assistant\", \"content\": example[\"completion_1\"]},\n",
    "]\n",
    "inputs_temp_1 = tokenizer.apply_chat_template(message_1, tokenize=False)\n",
    "inputs_1 = tokenizer(inputs_temp_1, return_tensors=\"pt\").to(model.device)\n",
    "detect_token_idx_1 = find_assistant_token_end(inputs_1[\"input_ids\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6554a428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nComplete the following sentence:\\nShe opened the door<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nand saw her friend waiting on the porch.<|eot_id|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_temp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b78adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 55])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_1[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d498835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_token_idx_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54c6395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs_1[\"input_ids\"][0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8f739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs_1)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "404064a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(logits[0, -1].argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ebd875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token idx: 44\n",
      "End token idx: 53\n"
     ]
    }
   ],
   "source": [
    "start_token_idx_1 = find_assistant_token_end(inputs_1[\"input_ids\"][0].tolist())\n",
    "end_token_idx_1 = len(inputs_1[\"input_ids\"][0]) - 2\n",
    "\n",
    "print(\"Start token idx:\", start_token_idx_1)\n",
    "print(\"End token idx:\", end_token_idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f6962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_1 = outputs.logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6b70ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token idx: 44\n",
      "Detect_Token: \n",
      "\n",
      "\n",
      "Target_Token: and\n",
      "Log Prob: -1.8671875\n",
      "Token idx: 45\n",
      "Detect_Token: and\n",
      "Target_Token:  saw\n",
      "Log Prob: -7.71875\n",
      "Token idx: 46\n",
      "Detect_Token:  saw\n",
      "Target_Token:  her\n",
      "Log Prob: -2.40625\n",
      "Token idx: 47\n",
      "Detect_Token:  her\n",
      "Target_Token:  friend\n",
      "Log Prob: -3.890625\n",
      "Token idx: 48\n",
      "Detect_Token:  friend\n",
      "Target_Token:  waiting\n",
      "Log Prob: -2.109375\n",
      "Token idx: 49\n",
      "Detect_Token:  waiting\n",
      "Target_Token:  on\n",
      "Log Prob: -0.9609375\n",
      "Token idx: 50\n",
      "Detect_Token:  on\n",
      "Target_Token:  the\n",
      "Log Prob: -7.915496826171875e-05\n",
      "Token idx: 51\n",
      "Detect_Token:  the\n",
      "Target_Token:  porch\n",
      "Log Prob: -0.58984375\n",
      "Token idx: 52\n",
      "Detect_Token:  porch\n",
      "Target_Token: .\n",
      "Log Prob: -3.546875\n"
     ]
    }
   ],
   "source": [
    "log_probs_1 = 1\n",
    "for token_idx in range(start_token_idx_1, end_token_idx_1): \n",
    "    print(\"Token idx:\", token_idx)\n",
    "    print(f\"Detect_Token: {tokenizer.decode(inputs_1['input_ids'][0][token_idx])}\")\n",
    "    print(f\"Target_Token: {tokenizer.decode(inputs_1['input_ids'][0][token_idx + 1])}\")\n",
    "    x = torch.log_softmax(logits_1[token_idx], dim=-1)[inputs_1[\"input_ids\"][0][token_idx + 1]].item()\n",
    "    print(f\"Log Prob: {x}\")\n",
    "    \n",
    "    log_probs_1 = log_probs_1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d7d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Log Prob: -0.045290280119493355\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Log Prob:\", log_probs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04a055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
