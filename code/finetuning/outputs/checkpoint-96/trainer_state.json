{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 96,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03187250996015936,
      "grad_norm": 6.900880813598633,
      "learning_rate": 0.0,
      "loss": 3.5872,
      "step": 1
    },
    {
      "epoch": 0.06374501992031872,
      "grad_norm": 6.995759010314941,
      "learning_rate": 4e-05,
      "loss": 3.6155,
      "step": 2
    },
    {
      "epoch": 0.09561752988047809,
      "grad_norm": 6.473848819732666,
      "learning_rate": 8e-05,
      "loss": 3.5042,
      "step": 3
    },
    {
      "epoch": 0.12749003984063745,
      "grad_norm": 4.707900524139404,
      "learning_rate": 0.00012,
      "loss": 3.1827,
      "step": 4
    },
    {
      "epoch": 0.1593625498007968,
      "grad_norm": 3.072964668273926,
      "learning_rate": 0.00016,
      "loss": 2.7851,
      "step": 5
    },
    {
      "epoch": 0.19123505976095617,
      "grad_norm": 2.7471210956573486,
      "learning_rate": 0.0002,
      "loss": 2.4018,
      "step": 6
    },
    {
      "epoch": 0.22310756972111553,
      "grad_norm": 2.774134874343872,
      "learning_rate": 0.0001978021978021978,
      "loss": 2.0284,
      "step": 7
    },
    {
      "epoch": 0.2549800796812749,
      "grad_norm": 2.735081672668457,
      "learning_rate": 0.00019560439560439562,
      "loss": 1.7195,
      "step": 8
    },
    {
      "epoch": 0.2868525896414343,
      "grad_norm": 2.7560863494873047,
      "learning_rate": 0.00019340659340659342,
      "loss": 1.2604,
      "step": 9
    },
    {
      "epoch": 0.3187250996015936,
      "grad_norm": 2.2659530639648438,
      "learning_rate": 0.00019120879120879122,
      "loss": 0.9915,
      "step": 10
    },
    {
      "epoch": 0.350597609561753,
      "grad_norm": 5.601502418518066,
      "learning_rate": 0.00018901098901098903,
      "loss": 0.8334,
      "step": 11
    },
    {
      "epoch": 0.38247011952191234,
      "grad_norm": 1.9242750406265259,
      "learning_rate": 0.00018681318681318683,
      "loss": 0.6735,
      "step": 12
    },
    {
      "epoch": 0.41434262948207173,
      "grad_norm": 1.173266053199768,
      "learning_rate": 0.00018461538461538463,
      "loss": 0.6281,
      "step": 13
    },
    {
      "epoch": 0.44621513944223107,
      "grad_norm": 0.7165664434432983,
      "learning_rate": 0.0001824175824175824,
      "loss": 0.5768,
      "step": 14
    },
    {
      "epoch": 0.47808764940239046,
      "grad_norm": 0.45480790734291077,
      "learning_rate": 0.00018021978021978024,
      "loss": 0.5011,
      "step": 15
    },
    {
      "epoch": 0.5099601593625498,
      "grad_norm": 0.40462741255760193,
      "learning_rate": 0.00017802197802197802,
      "loss": 0.5403,
      "step": 16
    },
    {
      "epoch": 0.5418326693227091,
      "grad_norm": 0.41201260685920715,
      "learning_rate": 0.00017582417582417582,
      "loss": 0.5054,
      "step": 17
    },
    {
      "epoch": 0.5737051792828686,
      "grad_norm": 0.3906667232513428,
      "learning_rate": 0.00017362637362637365,
      "loss": 0.5323,
      "step": 18
    },
    {
      "epoch": 0.6055776892430279,
      "grad_norm": 0.3896462321281433,
      "learning_rate": 0.00017142857142857143,
      "loss": 0.4666,
      "step": 19
    },
    {
      "epoch": 0.6374501992031872,
      "grad_norm": 0.3656957745552063,
      "learning_rate": 0.00016923076923076923,
      "loss": 0.5328,
      "step": 20
    },
    {
      "epoch": 0.6693227091633466,
      "grad_norm": 0.4569410979747772,
      "learning_rate": 0.00016703296703296706,
      "loss": 0.5172,
      "step": 21
    },
    {
      "epoch": 0.701195219123506,
      "grad_norm": 0.35144200921058655,
      "learning_rate": 0.00016483516483516484,
      "loss": 0.4737,
      "step": 22
    },
    {
      "epoch": 0.7330677290836654,
      "grad_norm": 0.3429569900035858,
      "learning_rate": 0.00016263736263736264,
      "loss": 0.4502,
      "step": 23
    },
    {
      "epoch": 0.7649402390438247,
      "grad_norm": 0.34795552492141724,
      "learning_rate": 0.00016043956043956044,
      "loss": 0.4842,
      "step": 24
    },
    {
      "epoch": 0.796812749003984,
      "grad_norm": 0.3640379011631012,
      "learning_rate": 0.00015824175824175824,
      "loss": 0.5145,
      "step": 25
    },
    {
      "epoch": 0.8286852589641435,
      "grad_norm": 0.32899487018585205,
      "learning_rate": 0.00015604395604395605,
      "loss": 0.4422,
      "step": 26
    },
    {
      "epoch": 0.8605577689243028,
      "grad_norm": 0.3460848331451416,
      "learning_rate": 0.00015384615384615385,
      "loss": 0.4927,
      "step": 27
    },
    {
      "epoch": 0.8924302788844621,
      "grad_norm": 0.3824787735939026,
      "learning_rate": 0.00015164835164835165,
      "loss": 0.469,
      "step": 28
    },
    {
      "epoch": 0.9243027888446215,
      "grad_norm": 0.4362020790576935,
      "learning_rate": 0.00014945054945054946,
      "loss": 0.5225,
      "step": 29
    },
    {
      "epoch": 0.9561752988047809,
      "grad_norm": 0.363044798374176,
      "learning_rate": 0.00014725274725274726,
      "loss": 0.4282,
      "step": 30
    },
    {
      "epoch": 0.9880478087649402,
      "grad_norm": 0.3845263421535492,
      "learning_rate": 0.00014505494505494506,
      "loss": 0.4427,
      "step": 31
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6489288806915283,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.4976,
      "step": 32
    },
    {
      "epoch": 1.0318725099601593,
      "grad_norm": 0.3832532465457916,
      "learning_rate": 0.00014065934065934067,
      "loss": 0.43,
      "step": 33
    },
    {
      "epoch": 1.0637450199203187,
      "grad_norm": 0.3927013576030731,
      "learning_rate": 0.00013846153846153847,
      "loss": 0.4804,
      "step": 34
    },
    {
      "epoch": 1.095617529880478,
      "grad_norm": 0.3822946846485138,
      "learning_rate": 0.00013626373626373628,
      "loss": 0.4316,
      "step": 35
    },
    {
      "epoch": 1.1274900398406373,
      "grad_norm": 0.4236310124397278,
      "learning_rate": 0.00013406593406593405,
      "loss": 0.44,
      "step": 36
    },
    {
      "epoch": 1.159362549800797,
      "grad_norm": 0.4190364181995392,
      "learning_rate": 0.00013186813186813188,
      "loss": 0.4614,
      "step": 37
    },
    {
      "epoch": 1.1912350597609562,
      "grad_norm": 0.3780387341976166,
      "learning_rate": 0.0001296703296703297,
      "loss": 0.4414,
      "step": 38
    },
    {
      "epoch": 1.2231075697211156,
      "grad_norm": 0.4210541546344757,
      "learning_rate": 0.00012747252747252746,
      "loss": 0.4396,
      "step": 39
    },
    {
      "epoch": 1.254980079681275,
      "grad_norm": 0.46047329902648926,
      "learning_rate": 0.00012527472527472527,
      "loss": 0.4191,
      "step": 40
    },
    {
      "epoch": 1.2868525896414342,
      "grad_norm": 0.4415229856967926,
      "learning_rate": 0.0001230769230769231,
      "loss": 0.3849,
      "step": 41
    },
    {
      "epoch": 1.3187250996015936,
      "grad_norm": 0.44010820984840393,
      "learning_rate": 0.00012087912087912087,
      "loss": 0.4298,
      "step": 42
    },
    {
      "epoch": 1.3505976095617531,
      "grad_norm": 0.5015981793403625,
      "learning_rate": 0.00011868131868131869,
      "loss": 0.4213,
      "step": 43
    },
    {
      "epoch": 1.3824701195219125,
      "grad_norm": 0.5114452242851257,
      "learning_rate": 0.0001164835164835165,
      "loss": 0.4225,
      "step": 44
    },
    {
      "epoch": 1.4143426294820718,
      "grad_norm": 0.5950540900230408,
      "learning_rate": 0.00011428571428571428,
      "loss": 0.4279,
      "step": 45
    },
    {
      "epoch": 1.4462151394422311,
      "grad_norm": 0.6482071280479431,
      "learning_rate": 0.0001120879120879121,
      "loss": 0.4972,
      "step": 46
    },
    {
      "epoch": 1.4780876494023905,
      "grad_norm": 0.5698085427284241,
      "learning_rate": 0.0001098901098901099,
      "loss": 0.4331,
      "step": 47
    },
    {
      "epoch": 1.5099601593625498,
      "grad_norm": 0.6483783721923828,
      "learning_rate": 0.0001076923076923077,
      "loss": 0.4873,
      "step": 48
    },
    {
      "epoch": 1.5418326693227091,
      "grad_norm": 0.662325382232666,
      "learning_rate": 0.0001054945054945055,
      "loss": 0.3792,
      "step": 49
    },
    {
      "epoch": 1.5737051792828685,
      "grad_norm": 0.7418249845504761,
      "learning_rate": 0.00010329670329670331,
      "loss": 0.4263,
      "step": 50
    },
    {
      "epoch": 1.6055776892430278,
      "grad_norm": 0.8055853247642517,
      "learning_rate": 0.0001010989010989011,
      "loss": 0.4349,
      "step": 51
    },
    {
      "epoch": 1.6374501992031871,
      "grad_norm": 0.9035026431083679,
      "learning_rate": 9.89010989010989e-05,
      "loss": 0.4251,
      "step": 52
    },
    {
      "epoch": 1.6693227091633465,
      "grad_norm": 0.9999870657920837,
      "learning_rate": 9.670329670329671e-05,
      "loss": 0.3838,
      "step": 53
    },
    {
      "epoch": 1.701195219123506,
      "grad_norm": 1.1465885639190674,
      "learning_rate": 9.450549450549451e-05,
      "loss": 0.3911,
      "step": 54
    },
    {
      "epoch": 1.7330677290836654,
      "grad_norm": 1.3050861358642578,
      "learning_rate": 9.230769230769232e-05,
      "loss": 0.4451,
      "step": 55
    },
    {
      "epoch": 1.7649402390438247,
      "grad_norm": 1.5734244585037231,
      "learning_rate": 9.010989010989012e-05,
      "loss": 0.3982,
      "step": 56
    },
    {
      "epoch": 1.796812749003984,
      "grad_norm": 1.7085624933242798,
      "learning_rate": 8.791208791208791e-05,
      "loss": 0.4119,
      "step": 57
    },
    {
      "epoch": 1.8286852589641436,
      "grad_norm": 1.9969173669815063,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.44,
      "step": 58
    },
    {
      "epoch": 1.860557768924303,
      "grad_norm": 2.3042328357696533,
      "learning_rate": 8.351648351648353e-05,
      "loss": 0.3943,
      "step": 59
    },
    {
      "epoch": 1.8924302788844622,
      "grad_norm": 2.723015546798706,
      "learning_rate": 8.131868131868132e-05,
      "loss": 0.3385,
      "step": 60
    },
    {
      "epoch": 1.9243027888446216,
      "grad_norm": 2.9492533206939697,
      "learning_rate": 7.912087912087912e-05,
      "loss": 0.3353,
      "step": 61
    },
    {
      "epoch": 1.956175298804781,
      "grad_norm": 2.518092393875122,
      "learning_rate": 7.692307692307693e-05,
      "loss": 0.3607,
      "step": 62
    },
    {
      "epoch": 1.9880478087649402,
      "grad_norm": 0.9022127389907837,
      "learning_rate": 7.472527472527473e-05,
      "loss": 0.3525,
      "step": 63
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.0152134895324707,
      "learning_rate": 7.252747252747253e-05,
      "loss": 0.3276,
      "step": 64
    },
    {
      "epoch": 2.0318725099601593,
      "grad_norm": 1.0110509395599365,
      "learning_rate": 7.032967032967034e-05,
      "loss": 0.3225,
      "step": 65
    },
    {
      "epoch": 2.0637450199203187,
      "grad_norm": 0.9384385347366333,
      "learning_rate": 6.813186813186814e-05,
      "loss": 0.3143,
      "step": 66
    },
    {
      "epoch": 2.095617529880478,
      "grad_norm": 0.72948157787323,
      "learning_rate": 6.593406593406594e-05,
      "loss": 0.3131,
      "step": 67
    },
    {
      "epoch": 2.1274900398406373,
      "grad_norm": 0.6493065357208252,
      "learning_rate": 6.373626373626373e-05,
      "loss": 0.2641,
      "step": 68
    },
    {
      "epoch": 2.1593625498007967,
      "grad_norm": 0.590445339679718,
      "learning_rate": 6.153846153846155e-05,
      "loss": 0.3142,
      "step": 69
    },
    {
      "epoch": 2.191235059760956,
      "grad_norm": 0.6412236094474792,
      "learning_rate": 5.9340659340659345e-05,
      "loss": 0.3203,
      "step": 70
    },
    {
      "epoch": 2.2231075697211153,
      "grad_norm": 0.6422457098960876,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.3032,
      "step": 71
    },
    {
      "epoch": 2.2549800796812747,
      "grad_norm": 0.7125194072723389,
      "learning_rate": 5.494505494505495e-05,
      "loss": 0.2674,
      "step": 72
    },
    {
      "epoch": 2.2868525896414345,
      "grad_norm": 0.7134453058242798,
      "learning_rate": 5.274725274725275e-05,
      "loss": 0.2671,
      "step": 73
    },
    {
      "epoch": 2.318725099601594,
      "grad_norm": 0.6863134503364563,
      "learning_rate": 5.054945054945055e-05,
      "loss": 0.3154,
      "step": 74
    },
    {
      "epoch": 2.350597609561753,
      "grad_norm": 0.5075445771217346,
      "learning_rate": 4.8351648351648355e-05,
      "loss": 0.3125,
      "step": 75
    },
    {
      "epoch": 2.3824701195219125,
      "grad_norm": 0.3921096622943878,
      "learning_rate": 4.615384615384616e-05,
      "loss": 0.2739,
      "step": 76
    },
    {
      "epoch": 2.414342629482072,
      "grad_norm": 0.48907357454299927,
      "learning_rate": 4.3956043956043955e-05,
      "loss": 0.285,
      "step": 77
    },
    {
      "epoch": 2.446215139442231,
      "grad_norm": 0.5961229205131531,
      "learning_rate": 4.1758241758241765e-05,
      "loss": 0.2397,
      "step": 78
    },
    {
      "epoch": 2.4780876494023905,
      "grad_norm": 0.7030783891677856,
      "learning_rate": 3.956043956043956e-05,
      "loss": 0.3048,
      "step": 79
    },
    {
      "epoch": 2.50996015936255,
      "grad_norm": 0.6609577536582947,
      "learning_rate": 3.7362637362637365e-05,
      "loss": 0.2892,
      "step": 80
    },
    {
      "epoch": 2.541832669322709,
      "grad_norm": 0.6887674331665039,
      "learning_rate": 3.516483516483517e-05,
      "loss": 0.3115,
      "step": 81
    },
    {
      "epoch": 2.5737051792828685,
      "grad_norm": 0.6807253360748291,
      "learning_rate": 3.296703296703297e-05,
      "loss": 0.2951,
      "step": 82
    },
    {
      "epoch": 2.605577689243028,
      "grad_norm": 0.7079256176948547,
      "learning_rate": 3.0769230769230774e-05,
      "loss": 0.2837,
      "step": 83
    },
    {
      "epoch": 2.637450199203187,
      "grad_norm": 0.676976203918457,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.3036,
      "step": 84
    },
    {
      "epoch": 2.6693227091633465,
      "grad_norm": 0.6884256601333618,
      "learning_rate": 2.6373626373626374e-05,
      "loss": 0.2799,
      "step": 85
    },
    {
      "epoch": 2.7011952191235062,
      "grad_norm": 0.640768826007843,
      "learning_rate": 2.4175824175824177e-05,
      "loss": 0.2928,
      "step": 86
    },
    {
      "epoch": 2.7330677290836656,
      "grad_norm": 0.682905912399292,
      "learning_rate": 2.1978021978021977e-05,
      "loss": 0.2513,
      "step": 87
    },
    {
      "epoch": 2.764940239043825,
      "grad_norm": 0.6198722720146179,
      "learning_rate": 1.978021978021978e-05,
      "loss": 0.2602,
      "step": 88
    },
    {
      "epoch": 2.7968127490039842,
      "grad_norm": 0.6031218767166138,
      "learning_rate": 1.7582417582417584e-05,
      "loss": 0.3127,
      "step": 89
    },
    {
      "epoch": 2.8286852589641436,
      "grad_norm": 0.5610666275024414,
      "learning_rate": 1.5384615384615387e-05,
      "loss": 0.2874,
      "step": 90
    },
    {
      "epoch": 2.860557768924303,
      "grad_norm": 0.5666805505752563,
      "learning_rate": 1.3186813186813187e-05,
      "loss": 0.227,
      "step": 91
    },
    {
      "epoch": 2.8924302788844622,
      "grad_norm": 0.523612916469574,
      "learning_rate": 1.0989010989010989e-05,
      "loss": 0.2647,
      "step": 92
    },
    {
      "epoch": 2.9243027888446216,
      "grad_norm": 0.4504701495170593,
      "learning_rate": 8.791208791208792e-06,
      "loss": 0.2823,
      "step": 93
    },
    {
      "epoch": 2.956175298804781,
      "grad_norm": 0.4896554946899414,
      "learning_rate": 6.5934065934065935e-06,
      "loss": 0.3094,
      "step": 94
    },
    {
      "epoch": 2.9880478087649402,
      "grad_norm": 0.46236634254455566,
      "learning_rate": 4.395604395604396e-06,
      "loss": 0.2725,
      "step": 95
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6599560379981995,
      "learning_rate": 2.197802197802198e-06,
      "loss": 0.2098,
      "step": 96
    }
  ],
  "logging_steps": 1,
  "max_steps": 96,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1637006917251072.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
