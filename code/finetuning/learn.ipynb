{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa438fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3879cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login, whoami\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0a6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.381 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Detected local model directory: /nlsasfs/home/isea/isea10/aansh/deception_detection/weights/unsloth/Llama-3.2-1B-Instruct\n",
      "Found HuggingFace hub cache directory: /nlsasfs/home/isea/isea10/.cache/huggingface/hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 1/1 [00:17<00:00, 17.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/nlsasfs/home/isea/isea10/aansh/introspection_weights/finetuned_llama_1b_merged`\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\"/nlsasfs/home/isea/isea10/aansh/introspection_weights/finetuned_llama_1b_multi_token\")\n",
    "\n",
    "model.save_pretrained_merged(\"/nlsasfs/home/isea/isea10/aansh/introspection_weights/finetuned_llama_1b_merged\", tokenizer, save_method=\"lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5bcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"unsloth/Llama-3.2-1B-Instruct\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a926ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-28 07:32:27,201] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/unsloth/Llama-3.2-1B-Instruct/tokenizer_config.json',\n",
       " '/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/unsloth/Llama-3.2-1B-Instruct/special_tokens_map.json',\n",
       " '/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/unsloth/Llama-3.2-1B-Instruct/chat_template.jinja',\n",
       " '/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/unsloth/Llama-3.2-1B-Instruct/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/nlsasfs/home/isea/isea10/aansh/deception_detection/weights/unsloth/Llama-3.2-1B-Instruct\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdbc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
